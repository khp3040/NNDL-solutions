{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1:Â Using neural nets to recognize handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 ([link](http://neuralnetworksanddeeplearning.com/chap1.html#exercises_191892)): sigmoid neurons simulating perceptrons, part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show that the behavior of a single perceptron doesn't change if we multiply its weight vector and its bias by a constant $c > 0$. The output of this perceptron is:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "  \\mbox{output} = \\left\\{ \n",
    "    \\begin{array}{ll} \n",
    "      0 & \\mbox{if } cw\\cdot x + cb \\leq 0 \\\\\n",
    "      1 & \\mbox{if } cw\\cdot x + cb > 0\n",
    "    \\end{array}\n",
    "  \\right.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Which is the same as the output without the multiplication by $c$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "  \\mbox{output} = \\left\\{ \n",
    "    \\begin{array}{ll} \n",
    "      0 & \\mbox{if } w\\cdot x + b \\leq 0 \\\\\n",
    "      1 & \\mbox{if } w\\cdot x + b > 0\n",
    "    \\end{array}\n",
    "  \\right.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Since this is true for every perceptron, the behavior of our neural network as a whole doesn't change either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2: sigmoid neurons simulating perceptrons, part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given sigmoid neuron with weight and bias multiplied by $c$, the activation function is $\\sigma(cw.x+cb) = \\frac{1}{1 + e^{-(cw.x+cb)}}$.\n",
    "\n",
    "For each perceptron, it is supposed that $w.x+b \\neq 0$.\n",
    "* If $w.x+b > 0$, then as $c \\rightarrow \\infty$, $\\frac{1}{1 + e^{-(cw.x+cb)}} \\rightarrow \\frac{1}{1 + 0} = 1$.\n",
    "* If $w.x+b < 0$, then as $c \\rightarrow \\infty$, $\\frac{1}{1 + e^{-(cw.x+cb)}} \\rightarrow \\frac{1}{1 + \\infty} = 0$.\n",
    "\n",
    "Therefore our sigmoid neuron gives the same output as a perceptron of parameters $(w,b)$ in the limit as $c \\rightarrow \\infty$.\n",
    "\n",
    "Since this is true for every neuron, our network as a whole has the same behavior as a network of perceptrons as $c \\rightarrow \\infty$.\n",
    "\n",
    "If however we have $w.x+b = 0$ for at least one sigmoid neuron, then its output is going to be $\\sigma(0) = \\frac{1}{1+e^0} = \\frac{1}{2}$ whatever the value of $c$. So we will never have the behavior of a perceptron, which only ever outputs 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The architecture of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple network to classify handwritten digits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
